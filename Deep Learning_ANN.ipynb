{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   32   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "data= pd.read_csv(\"E:\\\\ANISH\\\\DATA_SCIENCE\\\\Files\\\\Churn_Modelling.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting relevant features from the data for machine learning\n",
    "X= data.iloc[:,3:13]\n",
    "Y= data.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy variables\n",
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)\n",
    "\n",
    "#Concatenate the dummy variables to the original dataset\n",
    "X= pd.concat([X,geography, gender], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the irrelevant feature\n",
    "X=X.drop([\"Geography\",\"Gender\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the above dataset for train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size= 0.2, random_state= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the features of the train and test datasets\n",
    "sc= StandardScaler()\n",
    "X_train= sc.fit_transform(X_train)\n",
    "X_test= sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intitialising the ANN \n",
    "classifier= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the input and hidden layers\n",
    "classifier.add(Dense(units= 6, kernel_initializer=\"he_uniform\", activation='relu', input_dim=11,))\n",
    "classifier.add(Dense(units= 6, kernel_initializer=\"he_uniform\", activation='relu'))\n",
    "classifier.add(Dense(units= 1, kernel_initializer=\"glorot_uniform\", activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling\n",
    "#Since the output is binary(0 and 1), we use the loss function binary cross entropy\n",
    "classifier.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "536/536 [==============================] - 5s 4ms/step - loss: 0.6349 - accuracy: 0.6447 - val_loss: 0.4968 - val_accuracy: 0.7955\n",
      "Epoch 2/20\n",
      "536/536 [==============================] - 2s 4ms/step - loss: 0.4846 - accuracy: 0.7956 - val_loss: 0.4523 - val_accuracy: 0.7955\n",
      "Epoch 3/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.4516 - accuracy: 0.7841 - val_loss: 0.4166 - val_accuracy: 0.7955\n",
      "Epoch 4/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3851 - accuracy: 0.8050 - val_loss: 0.3945 - val_accuracy: 0.8266\n",
      "Epoch 5/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3802 - accuracy: 0.8324 - val_loss: 0.3894 - val_accuracy: 0.8285\n",
      "Epoch 6/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3711 - accuracy: 0.8478 - val_loss: 0.3851 - val_accuracy: 0.8379\n",
      "Epoch 7/20\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3846 - accuracy: 0.8392 - val_loss: 0.3859 - val_accuracy: 0.8421\n",
      "Epoch 8/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3883 - accuracy: 0.8377 - val_loss: 0.3826 - val_accuracy: 0.8448\n",
      "Epoch 9/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3566 - accuracy: 0.8541 - val_loss: 0.3818 - val_accuracy: 0.8470\n",
      "Epoch 10/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3708 - accuracy: 0.8421 - val_loss: 0.3805 - val_accuracy: 0.8451\n",
      "Epoch 11/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3441 - accuracy: 0.8549 - val_loss: 0.3780 - val_accuracy: 0.8463\n",
      "Epoch 12/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3610 - accuracy: 0.8525 - val_loss: 0.3767 - val_accuracy: 0.8440\n",
      "Epoch 13/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3439 - accuracy: 0.8549 - val_loss: 0.3754 - val_accuracy: 0.8478\n",
      "Epoch 14/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3577 - accuracy: 0.8553 - val_loss: 0.3747 - val_accuracy: 0.8482\n",
      "Epoch 15/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3529 - accuracy: 0.8504 - val_loss: 0.3728 - val_accuracy: 0.8497\n",
      "Epoch 16/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3584 - accuracy: 0.8511 - val_loss: 0.3713 - val_accuracy: 0.8497\n",
      "Epoch 17/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3325 - accuracy: 0.8614 - val_loss: 0.3706 - val_accuracy: 0.8489\n",
      "Epoch 18/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3472 - accuracy: 0.8559 - val_loss: 0.3701 - val_accuracy: 0.8508\n",
      "Epoch 19/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3514 - accuracy: 0.8537 - val_loss: 0.3668 - val_accuracy: 0.8531\n",
      "Epoch 20/20\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3530 - accuracy: 0.8531 - val_loss: 0.3687 - val_accuracy: 0.8516\n"
     ]
    }
   ],
   "source": [
    "#Fitting the ANN\n",
    "model= classifier.fit(X_train, Y_train, validation_split=0.33, batch_size=10, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the validation loss shows a gradual decrease through out the 20 epochs.\n",
    "Accuracy is above 85% at the end of the iterations.\n",
    "Interesting! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the Test dataset\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1467,  128],\n",
       "       [ 174,  231]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix= confusion_matrix(Y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is : 0.849\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score= accuracy_score(y_pred, Y_test)\n",
    "print(\"The accuracy is : {}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
